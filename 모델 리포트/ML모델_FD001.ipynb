{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc595e6",
   "metadata": {},
   "source": [
    "# 적용 예정 모델\n",
    "\n",
    "- Linear Regression\n",
    "- RandomForestRegressor\n",
    "- XGBoost Regressor\n",
    "- SVR\n",
    "- KNN Regressor\n",
    "\n",
    "### Branch\n",
    "1. BaseLine\n",
    "2. RUL_Clipping\n",
    "3. Scaling(Standard, MinMax, Robust)\n",
    "4. 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75967484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# 한글 인코딩 문제 해결\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86343b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\train_FD001.txt', sep=' ', header=None)\n",
    "test = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\test_FD001.txt', sep=' ', header=None)\n",
    "RUL = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\RUL_FD001.txt', sep=' ', header=None)\n",
    "train.drop(columns=[26, 27], inplace=True)\n",
    "test.drop(columns=[26, 27], inplace=True)\n",
    "RUL.drop(columns=[1], inplace=True)\n",
    "\n",
    "col_names = ['unit', 'cycle', 'setting_1', 'setting_2', 'setting_3', 'T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "train.columns = col_names\n",
    "test.columns = col_names\n",
    "RUL.columns = ['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb061fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUL 구하기\n",
    "def get_RUL(df):\n",
    "    rul_list = [x for x in df.groupby('unit')['cycle'].max()]\n",
    "    for unit in df['unit'].unique():\n",
    "        df.loc[df['unit']==unit, 'RUL'] = rul_list[unit-1] - df.loc[df['unit']==unit, 'cycle']\n",
    "\n",
    "get_RUL(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4148c026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit  cycle  setting_1  setting_2  setting_3      T2     T24      T30  \\\n",
       "0         1      1    -0.0007    -0.0004      100.0  518.67  641.82  1589.70   \n",
       "1         1      2     0.0019    -0.0003      100.0  518.67  642.15  1591.82   \n",
       "2         1      3    -0.0043     0.0003      100.0  518.67  642.35  1587.99   \n",
       "3         1      4     0.0007     0.0000      100.0  518.67  642.35  1582.79   \n",
       "4         1      5    -0.0019    -0.0002      100.0  518.67  642.37  1582.85   \n",
       "...     ...    ...        ...        ...        ...     ...     ...      ...   \n",
       "20626   100    196    -0.0004    -0.0003      100.0  518.67  643.49  1597.98   \n",
       "20627   100    197    -0.0016    -0.0005      100.0  518.67  643.54  1604.50   \n",
       "20628   100    198     0.0004     0.0000      100.0  518.67  643.42  1602.46   \n",
       "20629   100    199    -0.0011     0.0003      100.0  518.67  643.23  1605.26   \n",
       "20630   100    200    -0.0032    -0.0005      100.0  518.67  643.85  1600.38   \n",
       "\n",
       "           T50     P2  ...      NRf      NRc     BPR  farB  htBleed  Nf_dmd  \\\n",
       "0      1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03      392    2388   \n",
       "1      1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03      392    2388   \n",
       "2      1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03      390    2388   \n",
       "3      1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03      392    2388   \n",
       "4      1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03      393    2388   \n",
       "...        ...    ...  ...      ...      ...     ...   ...      ...     ...   \n",
       "20626  1428.63  14.62  ...  2388.26  8137.60  8.4956  0.03      397    2388   \n",
       "20627  1433.58  14.62  ...  2388.22  8136.50  8.5139  0.03      395    2388   \n",
       "20628  1428.18  14.62  ...  2388.24  8141.05  8.5646  0.03      398    2388   \n",
       "20629  1426.53  14.62  ...  2388.23  8139.29  8.5389  0.03      395    2388   \n",
       "20630  1432.14  14.62  ...  2388.26  8137.33  8.5036  0.03      396    2388   \n",
       "\n",
       "       PCNfR_dmd    W31      W32    RUL  \n",
       "0          100.0  39.06  23.4190  191.0  \n",
       "1          100.0  39.00  23.4236  190.0  \n",
       "2          100.0  38.95  23.3442  189.0  \n",
       "3          100.0  38.88  23.3739  188.0  \n",
       "4          100.0  38.90  23.4044  187.0  \n",
       "...          ...    ...      ...    ...  \n",
       "20626      100.0  38.49  22.9735    4.0  \n",
       "20627      100.0  38.30  23.1594    3.0  \n",
       "20628      100.0  38.44  22.9333    2.0  \n",
       "20629      100.0  38.29  23.0640    1.0  \n",
       "20630      100.0  38.37  23.0522    0.0  \n",
       "\n",
       "[20631 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae6643",
   "metadata": {},
   "source": [
    "- 전처리 1 : 제외할 만한 변동이 없는 컬럼 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71922e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 표준편차 분포로 제외할 만한 컬럼 찾기\n",
    "plt.figure(figsize=(12,6))\n",
    "std = train.drop(columns=['unit', 'cycle', 'RUL']).std()\n",
    "std.plot(kind='bar')\n",
    "plt.title('Train 데이터 표준편차 분포')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('표준편차')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30509823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr',\n",
       "       'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'farB', 'htBleed', 'Nf_dmd',\n",
       "       'PCNfR_dmd', 'W31', 'W32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21가지 센서를 모두 적용하겠습니다.\n",
    "features = train.columns[5:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a357a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65148e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>phi</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.24</td>\n",
       "      <td>1599.45</td>\n",
       "      <td>1415.79</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.69</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8213.28</td>\n",
       "      <td>8.4715</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1595.69</td>\n",
       "      <td>1422.05</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.05</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8210.85</td>\n",
       "      <td>8.4512</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.44</td>\n",
       "      <td>1593.15</td>\n",
       "      <td>1406.82</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.18</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8217.24</td>\n",
       "      <td>8.4569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.26</td>\n",
       "      <td>1594.99</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.33</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8220.48</td>\n",
       "      <td>8.4711</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13096 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit  cycle  setting_1  setting_2  setting_3      T2     T24      T30  \\\n",
       "0         1      1     0.0023     0.0003      100.0  518.67  643.02  1585.29   \n",
       "1         1      2    -0.0027    -0.0003      100.0  518.67  641.71  1588.45   \n",
       "2         1      3     0.0003     0.0001      100.0  518.67  642.46  1586.94   \n",
       "3         1      4     0.0042     0.0000      100.0  518.67  642.44  1584.12   \n",
       "4         1      5     0.0014     0.0000      100.0  518.67  642.51  1587.19   \n",
       "...     ...    ...        ...        ...        ...     ...     ...      ...   \n",
       "13091   100    194     0.0049     0.0000      100.0  518.67  643.24  1599.45   \n",
       "13092   100    195    -0.0011    -0.0001      100.0  518.67  643.22  1595.69   \n",
       "13093   100    196    -0.0006    -0.0003      100.0  518.67  643.44  1593.15   \n",
       "13094   100    197    -0.0038     0.0001      100.0  518.67  643.26  1594.99   \n",
       "13095   100    198     0.0013     0.0003      100.0  518.67  642.95  1601.62   \n",
       "\n",
       "           T50     P2  ...     phi      NRf      NRc     BPR  farB  htBleed  \\\n",
       "0      1398.21  14.62  ...  521.72  2388.03  8125.55  8.4052  0.03      392   \n",
       "1      1395.42  14.62  ...  522.16  2388.06  8139.62  8.3803  0.03      393   \n",
       "2      1401.34  14.62  ...  521.97  2388.03  8130.10  8.4441  0.03      393   \n",
       "3      1406.42  14.62  ...  521.38  2388.05  8132.90  8.3917  0.03      391   \n",
       "4      1401.92  14.62  ...  522.15  2388.03  8129.54  8.4031  0.03      390   \n",
       "...        ...    ...  ...     ...      ...      ...     ...   ...      ...   \n",
       "13091  1415.79  14.62  ...  520.69  2388.00  8213.28  8.4715  0.03      394   \n",
       "13092  1422.05  14.62  ...  521.05  2388.09  8210.85  8.4512  0.03      395   \n",
       "13093  1406.82  14.62  ...  521.18  2388.04  8217.24  8.4569  0.03      395   \n",
       "13094  1419.36  14.62  ...  521.33  2388.08  8220.48  8.4711  0.03      395   \n",
       "13095  1424.99  14.62  ...  521.07  2388.05  8214.64  8.4903  0.03      396   \n",
       "\n",
       "       Nf_dmd  PCNfR_dmd    W31      W32  \n",
       "0        2388      100.0  38.86  23.3735  \n",
       "1        2388      100.0  39.02  23.3916  \n",
       "2        2388      100.0  39.08  23.4166  \n",
       "3        2388      100.0  39.00  23.3737  \n",
       "4        2388      100.0  38.99  23.4130  \n",
       "...       ...        ...    ...      ...  \n",
       "13091    2388      100.0  38.65  23.1974  \n",
       "13092    2388      100.0  38.57  23.2771  \n",
       "13093    2388      100.0  38.62  23.2051  \n",
       "13094    2388      100.0  38.66  23.2699  \n",
       "13095    2388      100.0  38.70  23.1855  \n",
       "\n",
       "[13096 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시계열성을 따지지 않으므로 테스트셋의 마지막 사이클만 가져오기\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0914454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>P15</th>\n",
       "      <th>P30</th>\n",
       "      <th>Nf</th>\n",
       "      <th>Nc</th>\n",
       "      <th>epr</th>\n",
       "      <th>...</th>\n",
       "      <th>phi</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.58</td>\n",
       "      <td>1581.22</td>\n",
       "      <td>1398.91</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.42</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9056.40</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.79</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8130.11</td>\n",
       "      <td>8.4024</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.81</td>\n",
       "      <td>23.3552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.55</td>\n",
       "      <td>1586.59</td>\n",
       "      <td>1410.83</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.52</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>9044.77</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.74</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8126.90</td>\n",
       "      <td>8.4505</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.81</td>\n",
       "      <td>23.2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.88</td>\n",
       "      <td>1589.75</td>\n",
       "      <td>1418.89</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.59</td>\n",
       "      <td>2388.16</td>\n",
       "      <td>9049.26</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>520.83</td>\n",
       "      <td>2388.14</td>\n",
       "      <td>8131.46</td>\n",
       "      <td>8.4119</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.78</td>\n",
       "      <td>1594.53</td>\n",
       "      <td>1406.88</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.64</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>9051.30</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.88</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>8133.64</td>\n",
       "      <td>8.4634</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.58</td>\n",
       "      <td>23.2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.27</td>\n",
       "      <td>1589.94</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.29</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>9053.99</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.00</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8125.74</td>\n",
       "      <td>8.4362</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.75</td>\n",
       "      <td>23.4117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.30</td>\n",
       "      <td>1590.88</td>\n",
       "      <td>1397.94</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.99</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>9062.41</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>522.30</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8148.24</td>\n",
       "      <td>8.4110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.96</td>\n",
       "      <td>23.4606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.59</td>\n",
       "      <td>1582.96</td>\n",
       "      <td>1410.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.05</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9076.36</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.58</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8155.48</td>\n",
       "      <td>8.4500</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.61</td>\n",
       "      <td>23.2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.68</td>\n",
       "      <td>1599.51</td>\n",
       "      <td>1415.47</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.44</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>9062.34</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.53</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8146.39</td>\n",
       "      <td>8.4235</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.76</td>\n",
       "      <td>23.3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.00</td>\n",
       "      <td>1585.03</td>\n",
       "      <td>1397.98</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.75</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>9067.16</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.82</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8150.38</td>\n",
       "      <td>8.4003</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.48</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9155.03</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T2     T24      T30      T50     P2    P15     P30       Nf       Nc  \\\n",
       "0   518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
       "1   518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
       "2   518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
       "3   518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
       "4   518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
       "..     ...     ...      ...      ...    ...    ...     ...      ...      ...   \n",
       "95  518.67  642.30  1590.88  1397.94  14.62  21.61  553.99  2388.03  9062.41   \n",
       "96  518.67  642.59  1582.96  1410.92  14.62  21.61  554.05  2388.06  9076.36   \n",
       "97  518.67  642.68  1599.51  1415.47  14.62  21.61  553.44  2388.13  9062.34   \n",
       "98  518.67  642.00  1585.03  1397.98  14.62  21.61  554.75  2388.01  9067.16   \n",
       "99  518.67  642.95  1601.62  1424.99  14.62  21.61  552.48  2388.06  9155.03   \n",
       "\n",
       "    epr  ...     phi      NRf      NRc     BPR  farB  htBleed  Nf_dmd  \\\n",
       "0   1.3  ...  521.79  2388.06  8130.11  8.4024  0.03      393    2388   \n",
       "1   1.3  ...  521.74  2388.09  8126.90  8.4505  0.03      391    2388   \n",
       "2   1.3  ...  520.83  2388.14  8131.46  8.4119  0.03      395    2388   \n",
       "3   1.3  ...  521.88  2388.11  8133.64  8.4634  0.03      395    2388   \n",
       "4   1.3  ...  521.00  2388.15  8125.74  8.4362  0.03      394    2388   \n",
       "..  ...  ...     ...      ...      ...     ...   ...      ...     ...   \n",
       "95  1.3  ...  522.30  2388.01  8148.24  8.4110  0.03      391    2388   \n",
       "96  1.3  ...  521.58  2388.06  8155.48  8.4500  0.03      395    2388   \n",
       "97  1.3  ...  521.53  2388.09  8146.39  8.4235  0.03      394    2388   \n",
       "98  1.3  ...  521.82  2388.02  8150.38  8.4003  0.03      391    2388   \n",
       "99  1.3  ...  521.07  2388.05  8214.64  8.4903  0.03      396    2388   \n",
       "\n",
       "    PCNfR_dmd    W31      W32  \n",
       "0       100.0  38.81  23.3552  \n",
       "1       100.0  38.81  23.2618  \n",
       "2       100.0  38.93  23.2740  \n",
       "3       100.0  38.58  23.2581  \n",
       "4       100.0  38.75  23.4117  \n",
       "..        ...    ...      ...  \n",
       "95      100.0  38.96  23.4606  \n",
       "96      100.0  38.61  23.2953  \n",
       "97      100.0  38.76  23.3608  \n",
       "98      100.0  38.95  23.3595  \n",
       "99      100.0  38.70  23.1855  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['unit'].isin(test['unit'].unique())].groupby('unit').last()[features].reset_index().drop(columns=['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0017031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 21) (20631,)\n",
      "(100, 21) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = train['RUL']\n",
    "X_test = test.loc[test['unit'].isin(test['unit'].unique())].groupby('unit').last()[features].reset_index().drop(columns=['unit'])[features]\n",
    "y_test = RUL\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63efdf6",
   "metadata": {},
   "source": [
    "1. 베이스라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca164fb",
   "metadata": {},
   "source": [
    "- 모델 적용해보기 (Random Forest, LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d086d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "037decc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205dd17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===베이스라인 모델===\n",
      "Linear Regression 완료, RMSE: 31.9498, MAE: 25.5363, R2 Score: 0.4089\n",
      "Random Forest 완료, RMSE: 34.6986, MAE: 24.9521, R2 Score: 0.3028\n",
      "XGBoost 완료, RMSE: 41.0738, MAE: 26.9557, R2 Score: 0.0231\n",
      "SVR 완료, RMSE: 49.7081, MAE: 39.0054, R2 Score: -0.4308\n",
      "KNN 완료, RMSE: 36.3076, MAE: 28.0300, R2 Score: 0.2366\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Linear Regression  31.9498  25.5363    0.4089\n",
      "Random Forest      34.6986  24.9521    0.3028\n",
      "KNN                36.3076  28.0300    0.2366\n",
      "XGBoost            41.0738  26.9557    0.0231\n",
      "SVR                49.7081  39.0054   -0.4308\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models1 = {\n",
    "    'Linear Regression' : LinearRegression(n_jobs=-1),\n",
    "    'Random Forest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost' : XGBRegressor(random_State=42, n_jobs=-1),\n",
    "    'SVR' : SVR(kernel='rbf'),\n",
    "    'KNN' : KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "# 결과 저장 리스트\n",
    "results1 = []\n",
    "\n",
    "print(\"===베이스라인 모델===\")\n",
    "\n",
    "# 학습 실행\n",
    "\n",
    "for name, model in models1.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "\n",
    "    # 결과 저장\n",
    "    results1.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2 Score': r2\n",
    "    })\n",
    "\n",
    "    print(f'{name} 완료, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2 Score: {r2:.4f}')\n",
    "\n",
    "# 결과 표 출력\n",
    "baseline_df = pd.DataFrame(results1).set_index('Model')\n",
    "baseline_df = baseline_df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "print(\"\\n===모델 성능 비교===\")\n",
    "print(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b4725",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab188dd",
   "metadata": {},
   "source": [
    "- RUL Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef7ff9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train셋의 RUL 값을 120, 125, 130으로 클리핑하여 성능 비교\n",
    "y_train_clipped_120 = y_train.clip(upper=120)\n",
    "y_train_clipped_125 = y_train.clip(upper=125)\n",
    "y_train_clipped_130 = y_train.clip(upper=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4872b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_list = [y_train_clipped_120, y_train_clipped_125, y_train_clipped_130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "819f1ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 120.0 ---\n",
      "Linear Regression 완료, RMSE: 21.9226, MAE: 17.7643, R2 Score: 0.7217\n",
      "Random Forest 완료, RMSE: 18.1167, MAE: 13.3496, R2 Score: 0.8099\n",
      "XGBoost 완료, RMSE: 18.5077, MAE: 13.2504, R2 Score: 0.8016\n",
      "SVR 완료, RMSE: 49.7081, MAE: 39.0054, R2 Score: -0.4308\n",
      "KNN 완료, RMSE: 22.1103, MAE: 16.4400, R2 Score: 0.7169\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      18.1167  13.3496    0.8099\n",
      "XGBoost            18.5077  13.2504    0.8016\n",
      "Linear Regression  21.9226  17.7643    0.7217\n",
      "KNN                22.1103  16.4400    0.7169\n",
      "SVR                49.7081  39.0054   -0.4308\n",
      "--- 125.0 ---\n",
      "Linear Regression 완료, RMSE: 21.8947, MAE: 17.6153, R2 Score: 0.7224\n",
      "Random Forest 완료, RMSE: 18.3008, MAE: 13.4527, R2 Score: 0.8061\n",
      "XGBoost 완료, RMSE: 18.7233, MAE: 13.7375, R2 Score: 0.7970\n",
      "SVR 완료, RMSE: 49.7081, MAE: 39.0054, R2 Score: -0.4308\n",
      "KNN 완료, RMSE: 22.4651, MAE: 16.8960, R2 Score: 0.7077\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      18.3008  13.4527    0.8061\n",
      "XGBoost            18.7233  13.7375    0.7970\n",
      "Linear Regression  21.8947  17.6153    0.7224\n",
      "KNN                22.4651  16.8960    0.7077\n",
      "SVR                49.7081  39.0054   -0.4308\n",
      "--- 130.0 ---\n",
      "Linear Regression 완료, RMSE: 22.0549, MAE: 17.6648, R2 Score: 0.7183\n",
      "Random Forest 완료, RMSE: 18.8393, MAE: 13.8496, R2 Score: 0.7945\n",
      "XGBoost 완료, RMSE: 19.2445, MAE: 14.2786, R2 Score: 0.7855\n",
      "SVR 완료, RMSE: 49.7081, MAE: 39.0054, R2 Score: -0.4308\n",
      "KNN 완료, RMSE: 23.0027, MAE: 17.5060, R2 Score: 0.6936\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      18.8393  13.8496    0.7945\n",
      "XGBoost            19.2445  14.2786    0.7855\n",
      "Linear Regression  22.0549  17.6648    0.7183\n",
      "KNN                23.0027  17.5060    0.6936\n",
      "SVR                49.7081  39.0054   -0.4308\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models2 = {\n",
    "    'Linear Regression' : LinearRegression(n_jobs=-1),\n",
    "    'Random Forest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost' : XGBRegressor(random_State=42, n_jobs=-1),\n",
    "    'SVR' : SVR(kernel='rbf'),\n",
    "    'KNN' : KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "# 학습 실행\n",
    "\n",
    "for clip in clip_list:\n",
    "    y_train = clip\n",
    "    # 결과 저장 리스트\n",
    "    results = []\n",
    "    print(f\"--- {clip.max()} ---\")\n",
    "    for name, model in models2.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        r2 = r2_score(y_test, pred)\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r2\n",
    "        })\n",
    "\n",
    "        print(f'{name} 완료, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2 Score: {r2:.4f}')\n",
    "\n",
    "    # 결과 표 출력\n",
    "    df = pd.DataFrame(results).set_index('Model')\n",
    "    df = df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "    print(\"\\n===모델 성능 비교===\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeb381",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbcff47",
   "metadata": {},
   "source": [
    "- 스케일링 적용\n",
    "    - RUL_Clipping : 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2db2a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Scaling: StandardScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 21.8947)\n",
      "   ✅ Random Forest 완료 (RMSE: 18.2695)\n",
      "   ✅ XGBoost 완료 (RMSE: 18.7233)\n",
      "   ✅ SVR 완료 (RMSE: 19.3333)\n",
      "   ✅ KNN 완료 (RMSE: 18.5562)\n",
      "\n",
      "--- [Scaling: MinMaxScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 21.8947)\n",
      "   ✅ Random Forest 완료 (RMSE: 18.2994)\n",
      "   ✅ XGBoost 완료 (RMSE: 18.7233)\n",
      "   ✅ SVR 완료 (RMSE: 19.7762)\n",
      "   ✅ KNN 완료 (RMSE: 18.5501)\n",
      "\n",
      "--- [Scaling: RobustScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 21.8947)\n",
      "   ✅ Random Forest 완료 (RMSE: 18.2694)\n",
      "   ✅ XGBoost 완료 (RMSE: 18.7233)\n",
      "   ✅ SVR 완료 (RMSE: 19.3033)\n",
      "   ✅ KNN 완료 (RMSE: 19.1924)\n",
      "\n",
      "\n",
      "==================================================\n",
      "🏆 최종 성능 비교표 (Top 10)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>18.2694</td>\n",
       "      <td>13.4278</td>\n",
       "      <td>0.8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>18.2695</td>\n",
       "      <td>13.4322</td>\n",
       "      <td>0.8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>18.2994</td>\n",
       "      <td>13.4476</td>\n",
       "      <td>0.8061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>18.5501</td>\n",
       "      <td>13.6760</td>\n",
       "      <td>0.8007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>18.5562</td>\n",
       "      <td>13.6660</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18.7233</td>\n",
       "      <td>13.7375</td>\n",
       "      <td>0.7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18.7233</td>\n",
       "      <td>13.7375</td>\n",
       "      <td>0.7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18.7233</td>\n",
       "      <td>13.7375</td>\n",
       "      <td>0.7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19.1924</td>\n",
       "      <td>13.9020</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>19.3033</td>\n",
       "      <td>13.7044</td>\n",
       "      <td>0.7842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>19.3333</td>\n",
       "      <td>13.8063</td>\n",
       "      <td>0.7836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>19.7762</td>\n",
       "      <td>14.6206</td>\n",
       "      <td>0.7735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>21.8947</td>\n",
       "      <td>17.6153</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>21.8947</td>\n",
       "      <td>17.6153</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>21.8947</td>\n",
       "      <td>17.6153</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Scaler              Model     RMSE      MAE  R2 Score\n",
       "11    RobustScaler      Random Forest  18.2694  13.4278    0.8067\n",
       "1   StandardScaler      Random Forest  18.2695  13.4322    0.8067\n",
       "6     MinMaxScaler      Random Forest  18.2994  13.4476    0.8061\n",
       "9     MinMaxScaler                KNN  18.5501  13.6760    0.8007\n",
       "4   StandardScaler                KNN  18.5562  13.6660    0.8006\n",
       "2   StandardScaler            XGBoost  18.7233  13.7375    0.7970\n",
       "7     MinMaxScaler            XGBoost  18.7233  13.7375    0.7970\n",
       "12    RobustScaler            XGBoost  18.7233  13.7375    0.7970\n",
       "14    RobustScaler                KNN  19.1924  13.9020    0.7867\n",
       "13    RobustScaler                SVR  19.3033  13.7044    0.7842\n",
       "3   StandardScaler                SVR  19.3333  13.8063    0.7836\n",
       "8     MinMaxScaler                SVR  19.7762  14.6206    0.7735\n",
       "10    RobustScaler  Linear Regression  21.8947  17.6153    0.7224\n",
       "0   StandardScaler  Linear Regression  21.8947  17.6153    0.7224\n",
       "5     MinMaxScaler  Linear Regression  21.8947  17.6153    0.7224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# 적용할 스케일러\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# 모델 정의\n",
    "models3 = {\n",
    "    'Linear Regression': LinearRegression(n_jobs=-1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'KNN': KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "results3 = []\n",
    "\n",
    "# 첫 번째 루프: 스케일러 적용\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    print(f\"--- [Scaling: {scaler_name}] ---\")\n",
    "    \n",
    "    # 스케일링 수행 (Data Leakage 방지를 위해 Train으로 fit 후 Transform)\n",
    "    # X_train, X_test 변수가 이미 정의되어 있다고 가정합니다.\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 두 번째 루프: 모델 학습 및 평가\n",
    "    for model_name, model in models3.items():\n",
    "        \n",
    "        # 학습\n",
    "        model.fit(X_train_scaled, y_train_clipped_125)\n",
    "        \n",
    "        # 예측\n",
    "        pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # 평가\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        r2 = r2_score(y_test, pred)\n",
    "        \n",
    "        # 결과 저장 (어떤 스케일러인지 함께 기록)\n",
    "        results3.append({\n",
    "            'Scaler': scaler_name,\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r2\n",
    "        })\n",
    "        \n",
    "        print(f\"   ✅ {model_name} 완료 (RMSE: {rmse:.4f})\")\n",
    "    print(\"\") # 줄바꿈\n",
    "\n",
    "# 4. 결과 표 출력\n",
    "scaled_df = pd.DataFrame(results3)\n",
    "\n",
    "# RMSE 기준으로 오름차순 정렬 (성능 좋은 순서대로 보기)\n",
    "scaled_df = scaled_df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🏆 최종 성능 비교표 (Top 10)\")\n",
    "print(\"=\"*50)\n",
    "display(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fe1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
