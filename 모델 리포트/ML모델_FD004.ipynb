{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f8517e",
   "metadata": {},
   "source": [
    "# 적용 예정 모델\n",
    "\n",
    "- Linear Regression\n",
    "- RandomForestRegressor\n",
    "- XGBoost Regressor\n",
    "- SVR\n",
    "- KNN Regressor\n",
    "\n",
    "### Branch\n",
    "1. BaseLine\n",
    "2. RUL_Clipping\n",
    "3. Scaling(Standard, MinMax, Robust)\n",
    "4. 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62491bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# 한글 인코딩 문제 해결\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d587ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\train_FD004.txt', sep=' ', header=None)\n",
    "test = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\test_FD004.txt', sep=' ', header=None)\n",
    "RUL = pd.read_csv(r'C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\behrad3d\\nasa-cmaps\\versions\\1\\CMaps\\RUL_FD004.txt', sep=' ', header=None)\n",
    "train.drop(columns=[26, 27], inplace=True)\n",
    "test.drop(columns=[26, 27], inplace=True)\n",
    "RUL.drop(columns=[1], inplace=True)\n",
    "\n",
    "col_names = ['unit', 'cycle', 'setting_1', 'setting_2', 'setting_3', 'T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "train.columns = col_names\n",
    "test.columns = col_names\n",
    "RUL.columns = ['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f79ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUL 구하기\n",
    "def get_RUL(df):\n",
    "    rul_list = [x for x in df.groupby('unit')['cycle'].max()]\n",
    "    for unit in df['unit'].unique():\n",
    "        df.loc[df['unit']==unit, 'RUL'] = rul_list[unit-1] - df.loc[df['unit']==unit, 'cycle']\n",
    "\n",
    "get_RUL(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a995c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.73</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.97</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.08</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61244</th>\n",
       "      <td>249</td>\n",
       "      <td>251</td>\n",
       "      <td>9.9998</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>605.33</td>\n",
       "      <td>1516.36</td>\n",
       "      <td>1315.28</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.73</td>\n",
       "      <td>8185.69</td>\n",
       "      <td>8.4541</td>\n",
       "      <td>0.03</td>\n",
       "      <td>372</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.00</td>\n",
       "      <td>29.11</td>\n",
       "      <td>17.5234</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61245</th>\n",
       "      <td>249</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1598.92</td>\n",
       "      <td>1426.77</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.46</td>\n",
       "      <td>8185.47</td>\n",
       "      <td>8.2221</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.38</td>\n",
       "      <td>23.7151</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61246</th>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.68</td>\n",
       "      <td>1607.72</td>\n",
       "      <td>1430.56</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.48</td>\n",
       "      <td>8193.94</td>\n",
       "      <td>8.2525</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.78</td>\n",
       "      <td>23.8270</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61247</th>\n",
       "      <td>249</td>\n",
       "      <td>254</td>\n",
       "      <td>35.0046</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.77</td>\n",
       "      <td>1381.29</td>\n",
       "      <td>1148.18</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.83</td>\n",
       "      <td>8125.64</td>\n",
       "      <td>9.0515</td>\n",
       "      <td>0.02</td>\n",
       "      <td>337</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.26</td>\n",
       "      <td>9.0774</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61248</th>\n",
       "      <td>249</td>\n",
       "      <td>255</td>\n",
       "      <td>42.0030</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.85</td>\n",
       "      <td>1369.75</td>\n",
       "      <td>1147.45</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.66</td>\n",
       "      <td>8144.33</td>\n",
       "      <td>9.1207</td>\n",
       "      <td>0.02</td>\n",
       "      <td>333</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.66</td>\n",
       "      <td>6.4341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61249 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit  cycle  setting_1  setting_2  setting_3      T2     T24      T30  \\\n",
       "0         1      1    42.0049     0.8400      100.0  445.00  549.68  1343.43   \n",
       "1         1      2    20.0020     0.7002      100.0  491.19  606.07  1477.61   \n",
       "2         1      3    42.0038     0.8409      100.0  445.00  548.95  1343.12   \n",
       "3         1      4    42.0000     0.8400      100.0  445.00  548.70  1341.24   \n",
       "4         1      5    25.0063     0.6207       60.0  462.54  536.10  1255.23   \n",
       "...     ...    ...        ...        ...        ...     ...     ...      ...   \n",
       "61244   249    251     9.9998     0.2500      100.0  489.05  605.33  1516.36   \n",
       "61245   249    252     0.0028     0.0015      100.0  518.67  643.42  1598.92   \n",
       "61246   249    253     0.0029     0.0000      100.0  518.67  643.68  1607.72   \n",
       "61247   249    254    35.0046     0.8400      100.0  449.44  555.77  1381.29   \n",
       "61248   249    255    42.0030     0.8400      100.0  445.00  549.85  1369.75   \n",
       "\n",
       "           T50     P2  ...      NRf      NRc      BPR  farB  htBleed  Nf_dmd  \\\n",
       "0      1112.93   3.91  ...  2387.99  8074.83   9.3335  0.02      330    2212   \n",
       "1      1237.50   9.35  ...  2387.73  8046.13   9.1913  0.02      361    2324   \n",
       "2      1117.05   3.91  ...  2387.97  8066.62   9.4007  0.02      329    2212   \n",
       "3      1118.03   3.91  ...  2388.02  8076.05   9.3369  0.02      328    2212   \n",
       "4      1033.59   7.05  ...  2028.08  7865.80  10.8366  0.02      305    1915   \n",
       "...        ...    ...  ...      ...      ...      ...   ...      ...     ...   \n",
       "61244  1315.28  10.52  ...  2388.73  8185.69   8.4541  0.03      372    2319   \n",
       "61245  1426.77  14.62  ...  2388.46  8185.47   8.2221  0.03      396    2388   \n",
       "61246  1430.56  14.62  ...  2388.48  8193.94   8.2525  0.03      395    2388   \n",
       "61247  1148.18   5.48  ...  2388.83  8125.64   9.0515  0.02      337    2223   \n",
       "61248  1147.45   3.91  ...  2388.66  8144.33   9.1207  0.02      333    2212   \n",
       "\n",
       "       PCNfR_dmd    W31      W32    RUL  \n",
       "0         100.00  10.62   6.3670  320.0  \n",
       "1         100.00  24.37  14.6552  319.0  \n",
       "2         100.00  10.48   6.4213  318.0  \n",
       "3         100.00  10.54   6.4176  317.0  \n",
       "4          84.93  14.03   8.6754  316.0  \n",
       "...          ...    ...      ...    ...  \n",
       "61244     100.00  29.11  17.5234    4.0  \n",
       "61245     100.00  39.38  23.7151    3.0  \n",
       "61246     100.00  39.78  23.8270    2.0  \n",
       "61247     100.00  15.26   9.0774    1.0  \n",
       "61248     100.00  10.66   6.4341    0.0  \n",
       "\n",
       "[61249 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184c8fe",
   "metadata": {},
   "source": [
    "- 전처리 1 : 제외할 만한 변동이 없는 컬럼 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a72fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 표준편차 분포로 제외할 만한 컬럼 찾기\n",
    "plt.figure(figsize=(12,6))\n",
    "std = train.drop(columns=['unit', 'cycle', 'RUL']).std()\n",
    "std.plot(kind='bar')\n",
    "plt.title('Train 데이터 표준편차 분포')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('표준편차')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e6fe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr',\n",
       "       'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'farB', 'htBleed', 'Nf_dmd',\n",
       "       'PCNfR_dmd', 'W31', 'W32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21가지 센서를 모두 적용하겠습니다.\n",
    "features = train.columns[5:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36404a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c953d6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>phi</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0072</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.67</td>\n",
       "      <td>1481.04</td>\n",
       "      <td>1227.81</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>313.03</td>\n",
       "      <td>2387.78</td>\n",
       "      <td>8048.98</td>\n",
       "      <td>9.2229</td>\n",
       "      <td>0.02</td>\n",
       "      <td>362</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.31</td>\n",
       "      <td>14.7007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.9984</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.22</td>\n",
       "      <td>1256.17</td>\n",
       "      <td>1031.48</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>163.61</td>\n",
       "      <td>2028.09</td>\n",
       "      <td>7863.46</td>\n",
       "      <td>10.8632</td>\n",
       "      <td>0.02</td>\n",
       "      <td>306</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.36</td>\n",
       "      <td>8.5748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.23</td>\n",
       "      <td>1340.13</td>\n",
       "      <td>1105.88</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>129.98</td>\n",
       "      <td>2387.95</td>\n",
       "      <td>8071.13</td>\n",
       "      <td>9.3960</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.39</td>\n",
       "      <td>6.4365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0035</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.19</td>\n",
       "      <td>1339.70</td>\n",
       "      <td>1107.26</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>129.48</td>\n",
       "      <td>2387.90</td>\n",
       "      <td>8078.89</td>\n",
       "      <td>9.3594</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.56</td>\n",
       "      <td>6.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0079</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.10</td>\n",
       "      <td>1353.04</td>\n",
       "      <td>1117.80</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>181.82</td>\n",
       "      <td>2387.87</td>\n",
       "      <td>8057.83</td>\n",
       "      <td>9.3030</td>\n",
       "      <td>0.02</td>\n",
       "      <td>333</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>8.9326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41209</th>\n",
       "      <td>248</td>\n",
       "      <td>277</td>\n",
       "      <td>41.9991</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>550.30</td>\n",
       "      <td>1364.40</td>\n",
       "      <td>1129.17</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>130.87</td>\n",
       "      <td>2388.50</td>\n",
       "      <td>8112.61</td>\n",
       "      <td>9.4427</td>\n",
       "      <td>0.02</td>\n",
       "      <td>331</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.53</td>\n",
       "      <td>6.2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41210</th>\n",
       "      <td>248</td>\n",
       "      <td>278</td>\n",
       "      <td>20.0026</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>608.00</td>\n",
       "      <td>1494.75</td>\n",
       "      <td>1260.88</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>314.51</td>\n",
       "      <td>2388.33</td>\n",
       "      <td>8086.83</td>\n",
       "      <td>9.2772</td>\n",
       "      <td>0.02</td>\n",
       "      <td>366</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>14.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41211</th>\n",
       "      <td>248</td>\n",
       "      <td>279</td>\n",
       "      <td>34.9988</td>\n",
       "      <td>0.8413</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.92</td>\n",
       "      <td>1370.65</td>\n",
       "      <td>1130.97</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>182.76</td>\n",
       "      <td>2388.64</td>\n",
       "      <td>8100.84</td>\n",
       "      <td>9.3982</td>\n",
       "      <td>0.02</td>\n",
       "      <td>336</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.69</td>\n",
       "      <td>8.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41212</th>\n",
       "      <td>248</td>\n",
       "      <td>280</td>\n",
       "      <td>20.0027</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>608.19</td>\n",
       "      <td>1489.11</td>\n",
       "      <td>1256.25</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>314.17</td>\n",
       "      <td>2388.37</td>\n",
       "      <td>8085.24</td>\n",
       "      <td>9.2727</td>\n",
       "      <td>0.03</td>\n",
       "      <td>366</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.44</td>\n",
       "      <td>14.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41213</th>\n",
       "      <td>248</td>\n",
       "      <td>281</td>\n",
       "      <td>35.0075</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>556.40</td>\n",
       "      <td>1378.58</td>\n",
       "      <td>1140.70</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>181.88</td>\n",
       "      <td>2388.59</td>\n",
       "      <td>8098.17</td>\n",
       "      <td>9.3964</td>\n",
       "      <td>0.02</td>\n",
       "      <td>335</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.72</td>\n",
       "      <td>8.8502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41214 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit  cycle  setting_1  setting_2  setting_3      T2     T24      T30  \\\n",
       "0         1      1    20.0072     0.7000      100.0  491.19  606.67  1481.04   \n",
       "1         1      2    24.9984     0.6200       60.0  462.54  536.22  1256.17   \n",
       "2         1      3    42.0000     0.8420      100.0  445.00  549.23  1340.13   \n",
       "3         1      4    42.0035     0.8402      100.0  445.00  549.19  1339.70   \n",
       "4         1      5    35.0079     0.8400      100.0  449.44  555.10  1353.04   \n",
       "...     ...    ...        ...        ...        ...     ...     ...      ...   \n",
       "41209   248    277    41.9991     0.8401      100.0  445.00  550.30  1364.40   \n",
       "41210   248    278    20.0026     0.7005      100.0  491.19  608.00  1494.75   \n",
       "41211   248    279    34.9988     0.8413      100.0  449.44  555.92  1370.65   \n",
       "41212   248    280    20.0027     0.7000      100.0  491.19  608.19  1489.11   \n",
       "41213   248    281    35.0075     0.8402      100.0  449.44  556.40  1378.58   \n",
       "\n",
       "           T50    P2  ...     phi      NRf      NRc      BPR  farB  htBleed  \\\n",
       "0      1227.81  9.35  ...  313.03  2387.78  8048.98   9.2229  0.02      362   \n",
       "1      1031.48  7.05  ...  163.61  2028.09  7863.46  10.8632  0.02      306   \n",
       "2      1105.88  3.91  ...  129.98  2387.95  8071.13   9.3960  0.02      328   \n",
       "3      1107.26  3.91  ...  129.48  2387.90  8078.89   9.3594  0.02      328   \n",
       "4      1117.80  5.48  ...  181.82  2387.87  8057.83   9.3030  0.02      333   \n",
       "...        ...   ...  ...     ...      ...      ...      ...   ...      ...   \n",
       "41209  1129.17  3.91  ...  130.87  2388.50  8112.61   9.4427  0.02      331   \n",
       "41210  1260.88  9.35  ...  314.51  2388.33  8086.83   9.2772  0.02      366   \n",
       "41211  1130.97  5.48  ...  182.76  2388.64  8100.84   9.3982  0.02      336   \n",
       "41212  1256.25  9.35  ...  314.17  2388.37  8085.24   9.2727  0.03      366   \n",
       "41213  1140.70  5.48  ...  181.88  2388.59  8098.17   9.3964  0.02      335   \n",
       "\n",
       "       Nf_dmd  PCNfR_dmd    W31      W32  \n",
       "0        2324     100.00  24.31  14.7007  \n",
       "1        1915      84.93  14.36   8.5748  \n",
       "2        2212     100.00  10.39   6.4365  \n",
       "3        2212     100.00  10.56   6.2367  \n",
       "4        2223     100.00  14.85   8.9326  \n",
       "...       ...        ...    ...      ...  \n",
       "41209    2212     100.00  10.53   6.2620  \n",
       "41210    2324     100.00  24.33  14.6486  \n",
       "41211    2223     100.00  14.69   8.8389  \n",
       "41212    2324     100.00  24.44  14.6887  \n",
       "41213    2223     100.00  14.72   8.8502  \n",
       "\n",
       "[41214 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시계열성을 따지지 않으므로 테스트셋의 마지막 사이클만 가져오기\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9122ed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>P15</th>\n",
       "      <th>P30</th>\n",
       "      <th>Nf</th>\n",
       "      <th>Nc</th>\n",
       "      <th>epr</th>\n",
       "      <th>...</th>\n",
       "      <th>phi</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462.54</td>\n",
       "      <td>537.66</td>\n",
       "      <td>1264.31</td>\n",
       "      <td>1046.41</td>\n",
       "      <td>7.05</td>\n",
       "      <td>8.99</td>\n",
       "      <td>176.56</td>\n",
       "      <td>1915.66</td>\n",
       "      <td>8023.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>166.19</td>\n",
       "      <td>2028.53</td>\n",
       "      <td>7890.31</td>\n",
       "      <td>10.7615</td>\n",
       "      <td>0.02</td>\n",
       "      <td>308</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.41</td>\n",
       "      <td>8.6329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>445.00</td>\n",
       "      <td>549.96</td>\n",
       "      <td>1354.05</td>\n",
       "      <td>1133.55</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.72</td>\n",
       "      <td>139.03</td>\n",
       "      <td>2211.69</td>\n",
       "      <td>8310.36</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>130.17</td>\n",
       "      <td>2387.72</td>\n",
       "      <td>8073.44</td>\n",
       "      <td>9.3925</td>\n",
       "      <td>0.02</td>\n",
       "      <td>331</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.58</td>\n",
       "      <td>6.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>445.00</td>\n",
       "      <td>549.47</td>\n",
       "      <td>1341.06</td>\n",
       "      <td>1118.90</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.69</td>\n",
       "      <td>139.26</td>\n",
       "      <td>2212.04</td>\n",
       "      <td>8331.13</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>130.73</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>8095.58</td>\n",
       "      <td>9.2974</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.61</td>\n",
       "      <td>6.3488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>462.54</td>\n",
       "      <td>536.06</td>\n",
       "      <td>1253.49</td>\n",
       "      <td>1038.53</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.00</td>\n",
       "      <td>175.63</td>\n",
       "      <td>1915.39</td>\n",
       "      <td>8012.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>164.91</td>\n",
       "      <td>2028.30</td>\n",
       "      <td>7878.63</td>\n",
       "      <td>10.8396</td>\n",
       "      <td>0.02</td>\n",
       "      <td>306</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.41</td>\n",
       "      <td>8.5696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462.54</td>\n",
       "      <td>537.36</td>\n",
       "      <td>1263.60</td>\n",
       "      <td>1052.52</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.03</td>\n",
       "      <td>175.53</td>\n",
       "      <td>1915.36</td>\n",
       "      <td>8011.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>164.95</td>\n",
       "      <td>2028.24</td>\n",
       "      <td>7873.75</td>\n",
       "      <td>10.9094</td>\n",
       "      <td>0.02</td>\n",
       "      <td>307</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.19</td>\n",
       "      <td>8.6248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>491.19</td>\n",
       "      <td>607.94</td>\n",
       "      <td>1488.25</td>\n",
       "      <td>1255.52</td>\n",
       "      <td>9.35</td>\n",
       "      <td>13.66</td>\n",
       "      <td>334.72</td>\n",
       "      <td>2324.21</td>\n",
       "      <td>8761.89</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>314.85</td>\n",
       "      <td>2388.39</td>\n",
       "      <td>8094.02</td>\n",
       "      <td>9.2557</td>\n",
       "      <td>0.02</td>\n",
       "      <td>364</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.42</td>\n",
       "      <td>14.5261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>491.19</td>\n",
       "      <td>606.61</td>\n",
       "      <td>1481.48</td>\n",
       "      <td>1238.30</td>\n",
       "      <td>9.35</td>\n",
       "      <td>13.65</td>\n",
       "      <td>336.64</td>\n",
       "      <td>2323.93</td>\n",
       "      <td>8726.74</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>315.99</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8066.79</td>\n",
       "      <td>9.1421</td>\n",
       "      <td>0.02</td>\n",
       "      <td>363</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.70</td>\n",
       "      <td>14.8356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>491.19</td>\n",
       "      <td>606.82</td>\n",
       "      <td>1483.01</td>\n",
       "      <td>1241.32</td>\n",
       "      <td>9.35</td>\n",
       "      <td>13.65</td>\n",
       "      <td>334.86</td>\n",
       "      <td>2323.90</td>\n",
       "      <td>8722.26</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>315.22</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8060.86</td>\n",
       "      <td>9.1768</td>\n",
       "      <td>0.02</td>\n",
       "      <td>364</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.70</td>\n",
       "      <td>14.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>462.54</td>\n",
       "      <td>536.91</td>\n",
       "      <td>1261.67</td>\n",
       "      <td>1052.33</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.03</td>\n",
       "      <td>175.84</td>\n",
       "      <td>1915.31</td>\n",
       "      <td>8006.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>164.60</td>\n",
       "      <td>2028.24</td>\n",
       "      <td>7878.48</td>\n",
       "      <td>10.9332</td>\n",
       "      <td>0.02</td>\n",
       "      <td>307</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.21</td>\n",
       "      <td>8.4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>449.44</td>\n",
       "      <td>556.40</td>\n",
       "      <td>1378.58</td>\n",
       "      <td>1140.70</td>\n",
       "      <td>5.48</td>\n",
       "      <td>8.00</td>\n",
       "      <td>194.26</td>\n",
       "      <td>2223.50</td>\n",
       "      <td>8392.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>181.88</td>\n",
       "      <td>2388.59</td>\n",
       "      <td>8098.17</td>\n",
       "      <td>9.3964</td>\n",
       "      <td>0.02</td>\n",
       "      <td>335</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.72</td>\n",
       "      <td>8.8502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T2     T24      T30      T50    P2    P15     P30       Nf       Nc  \\\n",
       "0    462.54  537.66  1264.31  1046.41  7.05   8.99  176.56  1915.66  8023.10   \n",
       "1    445.00  549.96  1354.05  1133.55  3.91   5.72  139.03  2211.69  8310.36   \n",
       "2    445.00  549.47  1341.06  1118.90  3.91   5.69  139.26  2212.04  8331.13   \n",
       "3    462.54  536.06  1253.49  1038.53  7.05   9.00  175.63  1915.39  8012.46   \n",
       "4    462.54  537.36  1263.60  1052.52  7.05   9.03  175.53  1915.36  8011.76   \n",
       "..      ...     ...      ...      ...   ...    ...     ...      ...      ...   \n",
       "243  491.19  607.94  1488.25  1255.52  9.35  13.66  334.72  2324.21  8761.89   \n",
       "244  491.19  606.61  1481.48  1238.30  9.35  13.65  336.64  2323.93  8726.74   \n",
       "245  491.19  606.82  1483.01  1241.32  9.35  13.65  334.86  2323.90  8722.26   \n",
       "246  462.54  536.91  1261.67  1052.33  7.05   9.03  175.84  1915.31  8006.63   \n",
       "247  449.44  556.40  1378.58  1140.70  5.48   8.00  194.26  2223.50  8392.96   \n",
       "\n",
       "      epr  ...     phi      NRf      NRc      BPR  farB  htBleed  Nf_dmd  \\\n",
       "0    0.94  ...  166.19  2028.53  7890.31  10.7615  0.02      308    1915   \n",
       "1    1.02  ...  130.17  2387.72  8073.44   9.3925  0.02      331    2212   \n",
       "2    1.02  ...  130.73  2388.18  8095.58   9.2974  0.02      330    2212   \n",
       "3    0.94  ...  164.91  2028.30  7878.63  10.8396  0.02      306    1915   \n",
       "4    0.94  ...  164.95  2028.24  7873.75  10.9094  0.02      307    1915   \n",
       "..    ...  ...     ...      ...      ...      ...   ...      ...     ...   \n",
       "243  1.08  ...  314.85  2388.39  8094.02   9.2557  0.02      364    2324   \n",
       "244  1.08  ...  315.99  2388.03  8066.79   9.1421  0.02      363    2324   \n",
       "245  1.08  ...  315.22  2388.02  8060.86   9.1768  0.02      364    2324   \n",
       "246  0.94  ...  164.60  2028.24  7878.48  10.9332  0.02      307    1915   \n",
       "247  1.02  ...  181.88  2388.59  8098.17   9.3964  0.02      335    2223   \n",
       "\n",
       "     PCNfR_dmd    W31      W32  \n",
       "0        84.93  14.41   8.6329  \n",
       "1       100.00  10.58   6.4325  \n",
       "2       100.00  10.61   6.3488  \n",
       "3        84.93  14.41   8.5696  \n",
       "4        84.93  14.19   8.6248  \n",
       "..         ...    ...      ...  \n",
       "243     100.00  24.42  14.5261  \n",
       "244     100.00  24.70  14.8356  \n",
       "245     100.00  24.70  14.7371  \n",
       "246      84.93  14.21   8.4721  \n",
       "247     100.00  14.72   8.8502  \n",
       "\n",
       "[248 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['unit'].isin(test['unit'].unique())].groupby('unit').last()[features].reset_index().drop(columns=['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b72e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 21) (61249,)\n",
      "(248, 21) (248, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = train['RUL']\n",
    "X_test = test.loc[test['unit'].isin(test['unit'].unique())].groupby('unit').last()[features].reset_index().drop(columns=['unit'])[features]\n",
    "y_test = RUL\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6719ad",
   "metadata": {},
   "source": [
    "1. 베이스라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e551b8c",
   "metadata": {},
   "source": [
    "- 모델 적용해보기 (Random Forest, LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31883193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094597b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0151558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===베이스라인 모델===\n",
      "Linear Regression 완료, RMSE: 47.6456, MAE: 38.5324, R2 Score: 0.2364\n",
      "Random Forest 완료, RMSE: 43.2569, MAE: 31.5816, R2 Score: 0.3706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ds_study\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:13:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"random_State\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 완료, RMSE: 42.0864, MAE: 30.3634, R2 Score: 0.4042\n",
      "SVR 완료, RMSE: 65.2739, MAE: 54.6491, R2 Score: -0.4332\n",
      "KNN 완료, RMSE: 53.0159, MAE: 38.3355, R2 Score: 0.0545\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "XGBoost            42.0864  30.3634    0.4042\n",
      "Random Forest      43.2569  31.5816    0.3706\n",
      "Linear Regression  47.6456  38.5324    0.2364\n",
      "KNN                53.0159  38.3355    0.0545\n",
      "SVR                65.2739  54.6491   -0.4332\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models1 = {\n",
    "    'Linear Regression' : LinearRegression(n_jobs=-1),\n",
    "    'Random Forest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost' : XGBRegressor(random_State=42, n_jobs=-1),\n",
    "    'SVR' : SVR(kernel='rbf'),\n",
    "    'KNN' : KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "# 결과 저장 리스트\n",
    "results1 = []\n",
    "\n",
    "print(\"===베이스라인 모델===\")\n",
    "\n",
    "# 학습 실행\n",
    "\n",
    "for name, model in models1.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "\n",
    "    # 결과 저장\n",
    "    results1.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2 Score': r2\n",
    "    })\n",
    "\n",
    "    print(f'{name} 완료, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2 Score: {r2:.4f}')\n",
    "\n",
    "# 결과 표 출력\n",
    "baseline_df = pd.DataFrame(results1).set_index('Model')\n",
    "baseline_df = baseline_df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "print(\"\\n===모델 성능 비교===\")\n",
    "print(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92444da6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b69996b",
   "metadata": {},
   "source": [
    "- RUL Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd50478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train셋의 RUL 값을 120, 125, 130으로 클리핑하여 성능 비교\n",
    "y_train_clipped_120 = y_train.clip(upper=120)\n",
    "y_train_clipped_125 = y_train.clip(upper=125)\n",
    "y_train_clipped_130 = y_train.clip(upper=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac7167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_list = [y_train_clipped_120, y_train_clipped_125, y_train_clipped_130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f80977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 120.0 ---\n",
      "Linear Regression 완료, RMSE: 35.3106, MAE: 28.0560, R2 Score: 0.5806\n",
      "Random Forest 완료, RMSE: 31.2052, MAE: 23.0874, R2 Score: 0.6724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ds_study\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:19:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"random_State\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 완료, RMSE: 31.3775, MAE: 23.2908, R2 Score: 0.6688\n",
      "SVR 완료, RMSE: 63.6685, MAE: 53.4027, R2 Score: -0.3636\n",
      "KNN 완료, RMSE: 33.4636, MAE: 25.6887, R2 Score: 0.6233\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      31.2052  23.0874    0.6724\n",
      "XGBoost            31.3775  23.2908    0.6688\n",
      "KNN                33.4636  25.6887    0.6233\n",
      "Linear Regression  35.3106  28.0560    0.5806\n",
      "SVR                63.6685  53.4027   -0.3636\n",
      "--- 125.0 ---\n",
      "Linear Regression 완료, RMSE: 34.5615, MAE: 27.7461, R2 Score: 0.5982\n",
      "Random Forest 완료, RMSE: 30.2048, MAE: 22.6563, R2 Score: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ds_study\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:26:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"random_State\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 완료, RMSE: 30.2144, MAE: 22.7660, R2 Score: 0.6929\n",
      "SVR 완료, RMSE: 65.2322, MAE: 54.6174, R2 Score: -0.4314\n",
      "KNN 완료, RMSE: 32.8574, MAE: 25.3524, R2 Score: 0.6368\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      30.2048  22.6563    0.6931\n",
      "XGBoost            30.2144  22.7660    0.6929\n",
      "KNN                32.8574  25.3524    0.6368\n",
      "Linear Regression  34.5615  27.7461    0.5982\n",
      "SVR                65.2322  54.6174   -0.4314\n",
      "--- 130.0 ---\n",
      "Linear Regression 완료, RMSE: 34.0003, MAE: 27.5513, R2 Score: 0.6111\n",
      "Random Forest 완료, RMSE: 29.2692, MAE: 22.2453, R2 Score: 0.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ds_study\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:33:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"random_State\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 완료, RMSE: 29.5089, MAE: 21.8985, R2 Score: 0.7071\n",
      "SVR 완료, RMSE: 65.2739, MAE: 54.6491, R2 Score: -0.4332\n",
      "KNN 완료, RMSE: 32.4687, MAE: 25.1766, R2 Score: 0.6454\n",
      "\n",
      "===모델 성능 비교===\n",
      "                      RMSE      MAE  R2 Score\n",
      "Model                                        \n",
      "Random Forest      29.2692  22.2453    0.7118\n",
      "XGBoost            29.5089  21.8985    0.7071\n",
      "KNN                32.4687  25.1766    0.6454\n",
      "Linear Regression  34.0003  27.5513    0.6111\n",
      "SVR                65.2739  54.6491   -0.4332\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models2 = {\n",
    "    'Linear Regression' : LinearRegression(n_jobs=-1),\n",
    "    'Random Forest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost' : XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    'SVR' : SVR(kernel='rbf'),\n",
    "    'KNN' : KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "# 학습 실행\n",
    "\n",
    "for clip in clip_list:\n",
    "    y_train = clip\n",
    "    # 결과 저장 리스트\n",
    "    results = []\n",
    "    print(f\"--- {clip.max()} ---\")\n",
    "    for name, model in models2.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        r2 = r2_score(y_test, pred)\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r2\n",
    "        })\n",
    "\n",
    "        print(f'{name} 완료, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2 Score: {r2:.4f}')\n",
    "\n",
    "    # 결과 표 출력\n",
    "    df = pd.DataFrame(results).set_index('Model')\n",
    "    df = df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "    print(\"\\n===모델 성능 비교===\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61135cca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789b634",
   "metadata": {},
   "source": [
    "- 스케일링 적용\n",
    "    - RUL_Clipping : 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f11e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Scaling: StandardScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 34.5615)\n",
      "   ✅ Random Forest 완료 (RMSE: 30.2264)\n",
      "   ✅ XGBoost 완료 (RMSE: 30.2144)\n",
      "   ✅ SVR 완료 (RMSE: 45.6118)\n",
      "   ✅ KNN 완료 (RMSE: 32.2610)\n",
      "\n",
      "--- [Scaling: MinMaxScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 34.5615)\n",
      "   ✅ Random Forest 완료 (RMSE: 30.2253)\n",
      "   ✅ XGBoost 완료 (RMSE: 30.2144)\n",
      "   ✅ SVR 완료 (RMSE: 48.8717)\n",
      "   ✅ KNN 완료 (RMSE: 32.6754)\n",
      "\n",
      "--- [Scaling: RobustScaler] ---\n",
      "   ✅ Linear Regression 완료 (RMSE: 34.5615)\n",
      "   ✅ Random Forest 완료 (RMSE: 30.2344)\n",
      "   ✅ XGBoost 완료 (RMSE: 30.2144)\n",
      "   ✅ SVR 완료 (RMSE: 65.3266)\n",
      "   ✅ KNN 완료 (RMSE: 32.0418)\n",
      "\n",
      "\n",
      "==================================================\n",
      "🏆 최종 성능 비교표 (Top 10)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>30.2144</td>\n",
       "      <td>22.7660</td>\n",
       "      <td>0.6929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>30.2144</td>\n",
       "      <td>22.7660</td>\n",
       "      <td>0.6929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>30.2144</td>\n",
       "      <td>22.7660</td>\n",
       "      <td>0.6929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30.2253</td>\n",
       "      <td>22.6852</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30.2264</td>\n",
       "      <td>22.6848</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30.2344</td>\n",
       "      <td>22.7035</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>32.0418</td>\n",
       "      <td>24.0879</td>\n",
       "      <td>0.6546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>32.2610</td>\n",
       "      <td>24.7952</td>\n",
       "      <td>0.6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>KNN</td>\n",
       "      <td>32.6754</td>\n",
       "      <td>25.0153</td>\n",
       "      <td>0.6409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>34.5615</td>\n",
       "      <td>27.7461</td>\n",
       "      <td>0.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>34.5615</td>\n",
       "      <td>27.7461</td>\n",
       "      <td>0.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>34.5615</td>\n",
       "      <td>27.7461</td>\n",
       "      <td>0.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>45.6118</td>\n",
       "      <td>37.8353</td>\n",
       "      <td>0.3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>48.8717</td>\n",
       "      <td>41.0012</td>\n",
       "      <td>0.1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>SVR</td>\n",
       "      <td>65.3266</td>\n",
       "      <td>54.7442</td>\n",
       "      <td>-0.4355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Scaler              Model     RMSE      MAE  R2 Score\n",
       "2   StandardScaler            XGBoost  30.2144  22.7660    0.6929\n",
       "7     MinMaxScaler            XGBoost  30.2144  22.7660    0.6929\n",
       "12    RobustScaler            XGBoost  30.2144  22.7660    0.6929\n",
       "6     MinMaxScaler      Random Forest  30.2253  22.6852    0.6927\n",
       "1   StandardScaler      Random Forest  30.2264  22.6848    0.6927\n",
       "11    RobustScaler      Random Forest  30.2344  22.7035    0.6925\n",
       "14    RobustScaler                KNN  32.0418  24.0879    0.6546\n",
       "4   StandardScaler                KNN  32.2610  24.7952    0.6499\n",
       "9     MinMaxScaler                KNN  32.6754  25.0153    0.6409\n",
       "0   StandardScaler  Linear Regression  34.5615  27.7461    0.5982\n",
       "5     MinMaxScaler  Linear Regression  34.5615  27.7461    0.5982\n",
       "10    RobustScaler  Linear Regression  34.5615  27.7461    0.5982\n",
       "3   StandardScaler                SVR  45.6118  37.8353    0.3002\n",
       "8     MinMaxScaler                SVR  48.8717  41.0012    0.1966\n",
       "13    RobustScaler                SVR  65.3266  54.7442   -0.4355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# 적용할 스케일러\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# 모델 정의\n",
    "models3 = {\n",
    "    'Linear Regression': LinearRegression(n_jobs=-1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'KNN': KNeighborsRegressor(n_jobs=-1)\n",
    "}\n",
    "\n",
    "results3 = []\n",
    "\n",
    "# 첫 번째 루프: 스케일러 적용\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    print(f\"--- [Scaling: {scaler_name}] ---\")\n",
    "    \n",
    "    # 스케일링 수행 (Data Leakage 방지를 위해 Train으로 fit 후 Transform)\n",
    "    # X_train, X_test 변수가 이미 정의되어 있다고 가정합니다.\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 두 번째 루프: 모델 학습 및 평가\n",
    "    for model_name, model in models3.items():\n",
    "        \n",
    "        # 학습\n",
    "        model.fit(X_train_scaled, y_train_clipped_125)\n",
    "        \n",
    "        # 예측\n",
    "        pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # 평가\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        r2 = r2_score(y_test, pred)\n",
    "        \n",
    "        # 결과 저장 (어떤 스케일러인지 함께 기록)\n",
    "        results3.append({\n",
    "            'Scaler': scaler_name,\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r2\n",
    "        })\n",
    "        \n",
    "        print(f\"   ✅ {model_name} 완료 (RMSE: {rmse:.4f})\")\n",
    "    print(\"\") # 줄바꿈\n",
    "\n",
    "# 4. 결과 표 출력\n",
    "scaled_df = pd.DataFrame(results3)\n",
    "\n",
    "# RMSE 기준으로 오름차순 정렬 (성능 좋은 순서대로 보기)\n",
    "scaled_df = scaled_df.sort_values(by='RMSE', ascending=True).round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🏆 최종 성능 비교표 (Top 10)\")\n",
    "print(\"=\"*50)\n",
    "display(scaled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
